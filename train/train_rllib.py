import ray
from ray import tune
from ray.rllib.algorithms.ppo import PPOConfig
from scripts.delivery_env import DeliveryMultiAgentEnv
from scripts.agent_loader import load_agents_from_json_multi_order
from ray.rllib.env.wrappers.multi_agent_env_compatibility import MultiAgentEnvCompatibility
from ray.tune.registry import register_env
import gymnasium as gym
from gymnasium.spaces import Discrete, Box
import numpy as np
import json
import os  

# === ThÃ´ng tin mÃ´i trÆ°á»ng ===
ZONE = "cbd"
NET_FILE = os.path.abspath(f"data/raw/sumo/{ZONE}/{ZONE}.net.xml")
ROUTE_FILE = os.path.abspath(f"data/raw/sumo/{ZONE}/{ZONE}.weather_adjusted.rou.xml")
SUMOCFG_FILE = os.path.abspath(f"data/raw/sumo/{ZONE}/{ZONE}.sumocfg")
DELIVERY_PATH = os.path.abspath(f"data/raw/demand/{ZONE}/delivery_requests.json")

# === Load agent config tá»« JSON ===
with open(DELIVERY_PATH) as f:
    delivery_data = json.load(f)

if isinstance(delivery_data, dict):
    agents_config = delivery_data
elif isinstance(delivery_data, list):
    agents_config = load_agents_from_json_multi_order(DELIVERY_PATH)
else:
    raise ValueError("âŒ Äá»‹nh dáº¡ng delivery_requests.json khÃ´ng há»£p lá»‡.")

# === Äá»‹nh nghÄ©a hÃ m táº¡o mÃ´i trÆ°á»ng vÃ  bá»c MultiAgentEnvCompatibility ===
def env_creator(config):
    raw_env = DeliveryMultiAgentEnv(
        net_file=NET_FILE,
        route_file=ROUTE_FILE,
        sumocfg_file=SUMOCFG_FILE,
        agents_config=agents_config,
        gui=False,
        max_steps=1000,
    )

    # âœ… Quan trá»ng: confirm táº¡i Ä‘Ã¢y
    print("ðŸ§ª env_creator _agent_ids:", raw_env._agent_ids)

    return raw_env
test_env = env_creator({})
obs_space = test_env.observation_space
action_space = test_env.action_space

# === ÄÄƒng kÃ½ mÃ´i trÆ°á»ng RLlib ===
register_env("delivery-marl", env_creator)
def policy_mapping_fn(agent_id, episode=None, worker=None, **kwargs):
    return "default_policy"


# === Cáº¥u hÃ¬nh PPO ===
config = (
    PPOConfig()
    .environment("delivery-marl", env_config={})
    .framework("torch")
    .training(
        train_batch_size=512,
        lr=1e-4,
        gamma=0.99,
        model={"fcnet_hiddens": [128, 64]},
    )
    .multi_agent(
        policies={"default_policy": (None, obs_space, action_space, {})},
        policy_mapping_fn=policy_mapping_fn,
    )
    .rollouts(
        num_rollout_workers=0,        # Äáº·t = 0 Ä‘á»ƒ dá»… debug, Ä‘á»•i sang >0 khi Ä‘Ã£ á»•n Ä‘á»‹nh
        batch_mode="complete_episodes"
    )  
)

# === Khá»Ÿi Ä‘á»™ng Ray vÃ  huáº¥n luyá»‡n ===
ray.init(ignore_reinit_error=True)

tune.run("PPO", 
         config=config,
         stop={"training_iteration": 5})
